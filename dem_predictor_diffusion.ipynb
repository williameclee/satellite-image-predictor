{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "import dem_diffusion_model as demm\n",
    "# from dem_diffusion_model import DEMDiffusionModel\n",
    "from training_dataset import DEMDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256\n",
    "coarsen_factor = 2\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 30\n",
    "dem_src = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DEMDataset(dem_src, tile_size=tile_size, coarsen=2, rotate=True)\n",
    "\n",
    "model = demm.train_demdiffusionmodel(\n",
    "    \"load\",\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    subset_fraction=0.1e-2,\n",
    "    learning_rate=1e-3,\n",
    "    cond_dim=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.004):\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return np.clip(betas, 0, 0.999)\n",
    "\n",
    "\n",
    "def load_model(save_model, model, dataset, learning_rate, device):\n",
    "    if isinstance(save_model, str) and os.path.exists(save_model):\n",
    "        model_path = save_model\n",
    "        save_model = True\n",
    "    else:\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        model_path = os.path.join(\n",
    "            \"models\", f\"dem_ddpm-log{dataset.log_transform}-{dataset.tile_size}.pth\"\n",
    "        )\n",
    "    if save_model:\n",
    "        print(f\"Model will be saved to {model_path}\")\n",
    "\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.to(device)\n",
    "    elif isinstance(model, str) and os.path.exists(model):\n",
    "        model = UNet()\n",
    "        model.load_state_dict(torch.load(model, map_location=device))\n",
    "        print(f\"Model loaded successfully from {model_path}\")\n",
    "    elif isinstance(model, str) and model == \"load\":\n",
    "        model = UNet()\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading model from {model_path}\")\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        else:\n",
    "            print(f\"Best model not found at {model_path}, starting from scratch\")\n",
    "    elif isinstance(model, str) and model == \"new\":\n",
    "        model = UNet()\n",
    "\n",
    "    model.to(device)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    return model, optimiser, model_path\n",
    "\n",
    "\n",
    "def train_demdiffusionmodel(\n",
    "    model,\n",
    "    dataset,\n",
    "    batch_size=16,\n",
    "    learning_rate=1e-4,\n",
    "    num_epochs=20,\n",
    "    subset_fraction=1.0,\n",
    "    num_timesteps=100,\n",
    "    save_model=True,\n",
    "    device=(\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    ),\n",
    "    l2loss_weight=1.0,  # (slope-weighted) L2 loss weight\n",
    "    tvloss_weight=0.01,  # total variation loss weight\n",
    "    slope_scale=5.0,  # slope scaling factor\n",
    "):\n",
    "    if subset_fraction < 1.0:\n",
    "        num_epochs = round(round(num_epochs / subset_fraction))\n",
    "        print(\n",
    "            f\"Using {subset_fraction:.0%} of the dataset, training extended to {num_epochs} epochs\"\n",
    "        )\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load model\n",
    "    model, optimiser, model_path = load_model(\n",
    "        save_model, model, dataset, learning_rate, device\n",
    "    )\n",
    "\n",
    "    # Actual training starts here\n",
    "    loss_prev = np.inf\n",
    "\n",
    "    betas = cosine_beta_schedule(num_timesteps)\n",
    "    alphas_cumprod = np.cumprod(1.0 - betas)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        num_samples = int(len(dataset) * subset_fraction)\n",
    "        indices = random.sample(range(len(dataset)), num_samples)\n",
    "        sampler = SubsetRandomSampler(indices)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for x0 in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            x0 = x0.to(device)\n",
    "\n",
    "            # Sample time step\n",
    "            t = torch.randint(1, num_timesteps, (x0.size(0),), device=device).long()\n",
    "\n",
    "            # Retrieve alpha_cumprod for each t\n",
    "            alpha = torch.tensor(\n",
    "                alphas_cumprod[t.cpu().numpy()], dtype=torch.float32, device=device\n",
    "            ).view(-1, 1, 1, 1)\n",
    "\n",
    "            # Add noise to input\n",
    "            noise = torch.randn_like(x0)\n",
    "            xt = alpha.sqrt() * x0 + (1 - alpha).sqrt() * noise\n",
    "\n",
    "            # Predict the noise\n",
    "            pred_noise = model(xt, t.float() / num_timesteps)\n",
    "            mse_loss = F.mse_loss(pred_noise, noise)\n",
    "\n",
    "            # Optional: slope-weighted reconstruction loss (L_x0)\n",
    "            with torch.no_grad():\n",
    "                # Reconstruct x0 estimate\n",
    "                x0_pred = (xt - (1 - alpha).sqrt() * pred_noise) / alpha.sqrt()\n",
    "                slope = DDPMUNet.compute_slope_map(x0)\n",
    "                slope_weight = 1.0 + slope_scale * slope  # e.g. slope_scale = 5.0\n",
    "                weighted_l2 = ((x0_pred - x0) ** 2 * slope_weight).mean()\n",
    "\n",
    "            # TV regularisation on x0_pred\n",
    "            tv_reg = DDPMUNet.total_variation(x0_pred)\n",
    "\n",
    "            # Final combined loss\n",
    "            # loss = mse_loss\n",
    "            loss = mse_loss + l2loss_weight * weighted_l2 + tvloss_weight * tv_reg\n",
    "\n",
    "            # Optimise\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if loss > loss_prev * 100:\n",
    "            # learning_rate = learning_rate * 0.5\n",
    "            print(\n",
    "                f\"Epoch {round((epoch+1)*subset_fraction):04d}/{round(num_epochs*subset_fraction):04d}  Loss: {loss:.3f}. Loss diverged, back tracking.\"\n",
    "            )\n",
    "            model = UNet()\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.to(device)\n",
    "        else:\n",
    "            loss_prev = loss\n",
    "            if save_model:\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    model_path,\n",
    "                )\n",
    "                print(\n",
    "                    f\"Epoch {round((epoch+1)*subset_fraction):04d}/{round(num_epochs*subset_fraction):04d}  Loss: {loss:.3f}. Model saved\"\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Epoch {round((epoch+1)*subset_fraction):04d}/{round(num_epochs*subset_fraction):04d}  Loss: {loss:.3f}\"\n",
    "                )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = train_demdiffusionmodel(\n",
    "    \"load\",\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    subset_fraction=0.5e-2,\n",
    "    learning_rate=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load(f\"models/dem_ddpm-logTrue-{tile_size}.pth\", map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# --- 4. Visualisation (Denoising one sample) ---\n",
    "def denoise_sample(model, shape, steps=100, device=\"mps\"):\n",
    "    model.eval()\n",
    "    x = torch.randn(shape, device=device)\n",
    "    with torch.no_grad():\n",
    "        for i in reversed(range(1, steps + 1)):\n",
    "            t = torch.full((shape[0],), i / steps, device=device)\n",
    "            noise_pred = model(x, t)\n",
    "            alpha = 1 - 0.01 * t[:, None, None, None]\n",
    "            x = (x - (1 - alpha).sqrt() * noise_pred) / alpha.sqrt()\n",
    "            x = x.clamp(min=0.0, max=1.0)\n",
    "    return x.cpu()\n",
    "\n",
    "\n",
    "samples = denoise_sample(model, (4, 1, 128, 128))\n",
    "for i in range(4):\n",
    "    dem = samples[i][0].numpy()\n",
    "    # undo base-10 log transform\n",
    "    dem = 10 ** (dem * 4) - 1\n",
    "    plt.imshow(dem, cmap=\"terrain\")\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Generated DEM #{i+1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEMDataset import DEMDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = DEMDataset(\n",
    "    \"training-data/unet-input-dem.tif\",\n",
    "    tile_size=256,\n",
    "    rotate=False,\n",
    "    normalise_factor=1e4,\n",
    "    log_transform=True,\n",
    ")\n",
    "\n",
    "# Visualise a sample from the dataset\n",
    "iSample = np.random.randint(0, len(dataset))\n",
    "sample = dataset[iSample][0].numpy()\n",
    "plt.imshow(sample, cmap=\"terrain\")\n",
    "plt.clim(0, 1)\n",
    "plt.colorbar()\n",
    "plt.title(f\"DEM #{iSample}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = np.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return np.clip(betas, 0, 0.999)\n",
    "\n",
    "\n",
    "betas = cosine_beta_schedule(100)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = np.cumprod(alphas)\n",
    "\n",
    "\n",
    "def visualize_denoising(\n",
    "    model, dataset, alphas_cumprod, device=\"mps\", num_samples=3, timestep=None\n",
    "):\n",
    "    model.eval()\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    alpha_array = np.array(alphas_cumprod, dtype=np.float32)\n",
    "\n",
    "    for idx in indices:\n",
    "        x0 = dataset[idx].unsqueeze(0).to(device)  # [1, 1, H, W]\n",
    "\n",
    "        # Choose timestep t\n",
    "        T = len(alpha_array)\n",
    "        if timestep is None:\n",
    "            t_val = random.randint(1, T - 1)\n",
    "        else:\n",
    "            t_val = timestep\n",
    "        t = torch.tensor([t_val / T], dtype=torch.float32, device=device)  # [1]\n",
    "\n",
    "        # Add noise\n",
    "        alpha_t = torch.tensor(\n",
    "            alpha_array[t_val], dtype=torch.float32, device=device\n",
    "        ).view(1, 1, 1, 1)\n",
    "        noise = torch.randn_like(x0)\n",
    "        xt = alpha_t.sqrt() * x0 + (1 - alpha_t).sqrt() * noise\n",
    "\n",
    "        # Predict and denoise\n",
    "        with torch.no_grad():\n",
    "            pred_noise = model(xt, t)\n",
    "            x0_pred = (xt - (1 - alpha_t).sqrt() * pred_noise) / alpha_t.sqrt()\n",
    "\n",
    "        # Convert to numpy for plotting\n",
    "        x0_np = x0.squeeze().cpu().numpy()\n",
    "        xt_np = xt.squeeze().cpu().numpy()\n",
    "        x0_pred_np = x0_pred.squeeze().cpu().numpy()\n",
    "        diff_np = x0_np - x0_pred_np\n",
    "\n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "        for ax in axes:\n",
    "            ax.axis(\"off\")\n",
    "        im0 = axes[0].imshow(x0_np, cmap=\"terrain\")\n",
    "        im0.set_clim(0, 1)\n",
    "        axes[0].set_title(\"Original DEM $x_0$\")\n",
    "        im1 = axes[1].imshow(xt_np, cmap=\"terrain\")\n",
    "        im1.set_clim(0, 1)\n",
    "        axes[1].set_title(f\"Noisy Input $x_t$ (t={t_val})\")\n",
    "        im2 = axes[2].imshow(x0_pred_np, cmap=\"terrain\")\n",
    "        im2.set_clim(0, 1)\n",
    "        axes[2].set_title(\"Predicted DEM ${x_0}'$\")\n",
    "        im = axes[3].imshow(diff_np, cmap=\"coolwarm\")\n",
    "        im.set_clim(-0.5, 0.5)\n",
    "        axes[3].set_title(\"Residual Error $x_0 - {x_0}'$\")\n",
    "        fig.colorbar(im, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "dataset = DEMDataset(\n",
    "    \"training-data/unet-input-dem.tif\",\n",
    "    tile_size=256,\n",
    "    rotate=False,\n",
    "    normalise_factor=1e4,\n",
    "    log_transform=True,\n",
    ")\n",
    "\n",
    "device=(\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "model = UNet()\n",
    "model.load_state_dict(\n",
    "    torch.load(f\"models/dem_ddpm-log{dataset.log_transform}-{dataset.tile_size}.pth\", map_location=device)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "visualize_denoising(model, dataset, alphas_cumprod, device=\"mps\", timestep=75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
