{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKeVtrOtfeL-"
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1743316750826,
     "user": {
      "displayName": "En-Chi “Will” Lee",
      "userId": "10244781745410421206"
     },
     "user_tz": 420
    },
    "id": "YVGQHr_mfm-R"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pytorch_msssim import ssim\n",
    "import random\n",
    "\n",
    "sys.path.append(\"models\")\n",
    "from UNetGenerator import UNetGenerator\n",
    "from UNetDiscriminator import UNetDiscriminator\n",
    "from SatelliteDataset import SatelliteDataset\n",
    "\n",
    "print(\n",
    "    f\"PyTorch version: {torch.__version__}, MPS available: {torch.backends.mps.is_available()}\"\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from landcovervis import landcover, landcovernorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1743316751186,
     "user": {
      "displayName": "En-Chi “Will” Lee",
      "userId": "10244781745410421206"
     },
     "user_tz": 420
    },
    "id": "iQlnXHOhfqOt"
   },
   "outputs": [],
   "source": [
    "tile_size = 256  # Size of each tile (256x256)\n",
    "# in_channels = 2  # DEM, land cover\n",
    "in_channels = 3  # DEM, land cover, hillshade\n",
    "\n",
    "input_path = \"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/training-data/unet-input.tif\"\n",
    "target_path = \"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/training-data/unet-target.tif\"\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1743316752091,
     "user": {
      "displayName": "En-Chi “Will” Lee",
      "userId": "10244781745410421206"
     },
     "user_tz": 420
    },
    "id": "IVoo1_ymgzvv"
   },
   "outputs": [],
   "source": [
    "genmodel = UNetGenerator(in_channels=in_channels).to(device)\n",
    "discmodel = UNetDiscriminator(in_channels=in_channels + 3).to(device)\n",
    "\n",
    "genmodel.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/unet-T{tile_size}C{in_channels}_best.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "# genmodel.load_state_dict(\n",
    "#     torch.load(\n",
    "#         f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/pix2pix-T{tile_size}C{in_channels}_best.pth\",\n",
    "#         map_location=device,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# discmodel.load_state_dict(\n",
    "#     torch.load(\n",
    "#         f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/pix2pix_disc-T{tile_size}C{in_channels}.pth\",\n",
    "#         map_location=device,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "g_opt = torch.optim.Adam(genmodel.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "d_opt = torch.optim.Adam(discmodel.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "criterion_gan = nn.BCELoss()\n",
    "criterion_l1 = nn.L1Loss()\n",
    "\n",
    "# Original dataset\n",
    "dataset = SatelliteDataset(\n",
    "    input_path,\n",
    "    target_path,\n",
    "    tile_size=tile_size,\n",
    "    in_channels=in_channels,\n",
    "    rotate=True,\n",
    "    # forest_gamma=1.4,\n",
    ")\n",
    "\n",
    "# Split\n",
    "val_size = int(0.1 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "best_psnr = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQHI_mDDiv2j",
    "outputId": "0ef44bd9-b1f2-4f7e-8d79-830d800db84f"
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "subset_fraction = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    num_samples = int(len(dataset) * subset_fraction)\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    sampler = SubsetRandomSampler(indices)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    \n",
    "    genmodel.train()\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Discriminator\n",
    "        discmodel.zero_grad()\n",
    "        real_pair = torch.cat([x, y], dim=1)\n",
    "        fake_y = genmodel(x).detach()\n",
    "        fake_pair = torch.cat([x, fake_y], dim=1)\n",
    "        real_output = discmodel(real_pair)\n",
    "        fake_output = discmodel(fake_pair)\n",
    "        real_label = torch.ones_like(real_output)\n",
    "        fake_label = torch.zeros_like(fake_output)\n",
    "        d_real_loss = criterion_gan(real_output, real_label)\n",
    "        d_fake_loss = criterion_gan(fake_output, fake_label)\n",
    "        d_loss = (d_real_loss + d_fake_loss) * 0.5\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        # Generator\n",
    "        genmodel.zero_grad()\n",
    "        fake_y = genmodel(x)\n",
    "        fake_pair = torch.cat([x, fake_y], dim=1)\n",
    "        g_gan_loss = criterion_gan(discmodel(fake_pair), real_label)\n",
    "        g_l1_loss = criterion_l1(fake_y, y)\n",
    "        g_loss = 0.1 * g_gan_loss + 100 * g_l1_loss\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "    # Validation Metrics\n",
    "    genmodel.eval()\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            pred_val = genmodel(x_val)\n",
    "            total_psnr += 20 * torch.log10(\n",
    "                1.0 / torch.sqrt(nn.functional.mse_loss(pred_val, y_val))\n",
    "            )\n",
    "            total_ssim += ssim(pred_val, y_val, data_range=1.0, size_average=True)\n",
    "\n",
    "    avg_psnr = total_psnr / len(val_loader)\n",
    "    avg_ssim = total_ssim / len(val_loader)\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f} | PSNR: {avg_psnr:.2f} | SSIM: {avg_ssim:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save best generator\n",
    "    if avg_psnr > best_psnr:\n",
    "        best_psnr = avg_psnr\n",
    "        torch.save(\n",
    "            genmodel.state_dict(),\n",
    "            f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/pix2pix-T{tile_size}C{in_channels}_best.pth\",\n",
    "        )\n",
    "        print(\n",
    "            f\"New best model saved with PSNR: {avg_psnr:.2f} at epoch {epoch+1}/{epochs}\"\n",
    "        )\n",
    "\n",
    "    nTests = 2\n",
    "    with torch.no_grad():\n",
    "        x, y = next(iter(train_loader))\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = genmodel(x).cpu().numpy()\n",
    "        fig, axes = plt.subplots(\n",
    "            nTests, 2 + in_channels, figsize=(5 * (2 + in_channels), nTests * 3 + 1)\n",
    "        )\n",
    "        for i in range(nTests):\n",
    "            axes[i, 0].imshow(x[i][0].cpu(), cmap=\"terrain\", vmin=0, vmax=4000)\n",
    "            axes[i, 1].imshow(x[i][1].cpu(), cmap=landcover, norm=landcovernorm)\n",
    "            if in_channels == 3:\n",
    "                axes[i, 2].imshow(\n",
    "                    x[i][2].cpu(), cmap=\"gray\", vmin=0, vmax=1\n",
    "                )  # Hillshade\n",
    "            axes[i, in_channels].imshow(np.transpose(pred[i], (1, 2, 0)))\n",
    "            axes[i, in_channels + 1].imshow(y[i].cpu().numpy().transpose(1, 2, 0))\n",
    "\n",
    "            # Cosmetic\n",
    "            for j in range(4):\n",
    "                axes[i, j].set_xticks([])\n",
    "                axes[i, j].set_yticks([])\n",
    "                axes[i, 0].set_axis_off()\n",
    "\n",
    "            if i == 0:\n",
    "                axes[i, 0].set_title(\"DEM\")\n",
    "                axes[i, 1].set_title(\"Land Cover\")\n",
    "                if in_channels == 3:\n",
    "                    axes[i, 2].set_title(\"Hillshade\")\n",
    "                axes[i, in_channels].set_title(\"Predicted RGB\")\n",
    "                axes[i, in_channels + 1].set_title(\"True RGB\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "torch.save(\n",
    "    genmodel.state_dict(),\n",
    "    f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/pix2pix-T{tile_size}C{in_channels}.pth\",\n",
    ")\n",
    "torch.save(\n",
    "    discmodel.state_dict(),\n",
    "    f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/pix2pix_disc-T{tile_size}C{in_channels}.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11922,
     "status": "aborted",
     "timestamp": 1743316752911,
     "user": {
      "displayName": "En-Chi “Will” Lee",
      "userId": "10244781745410421206"
     },
     "user_tz": 420
    },
    "id": "uWTIMdpehLii"
   },
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "tile_size = 256\n",
    "\n",
    "dataset = SatelliteDataset(\n",
    "    input_path,\n",
    "    target_path,\n",
    "    tile_size=tile_size,\n",
    "    in_channels=in_channels,\n",
    "    rotate=False,\n",
    ")\n",
    "\n",
    "genmodel_unet = UNetGenerator(in_channels=in_channels).to(device)\n",
    "genmodel_unet.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/unet-T{tile_size}C{in_channels}_best.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "genmodel_unet.eval()\n",
    "\n",
    "genmodel_pix2pix = UNetGenerator(in_channels=3).to(device)\n",
    "genmodel_pix2pix.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"/Users/williameclee/Documents/college/MATH/2025_1-MATH496T/satellite-image-predictor/models/pix2pix-T{tile_size}C{in_channels}_best.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    ")\n",
    "genmodel_pix2pix.eval()\n",
    "\n",
    "testId = [1158, 1171, 64]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_list, y_list = [], []\n",
    "    for iTest in testId:  # Choose specific sample indices here\n",
    "        x_item, y_item = dataset[iTest]\n",
    "        x_list.append(x_item)\n",
    "        y_list.append(y_item)\n",
    "\n",
    "    x = torch.stack(x_list).to(device)\n",
    "    y = torch.stack(y_list).to(device)\n",
    "\n",
    "    pred_unet = genmodel_unet(x).cpu().numpy()\n",
    "    pred_pix2pix = genmodel_pix2pix(x).cpu().numpy()\n",
    "\n",
    "    for iTest in range(len(testId)):\n",
    "        plt.rcParams.update({\"font.size\": 6})\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(5, 3))\n",
    "        axes[0, 0].imshow(x[iTest][0].cpu(), cmap=\"terrain\", vmin=0, vmax=4000)\n",
    "        axes[0, 1].imshow(x[iTest][1].cpu(), cmap=landcover, norm=landcovernorm)\n",
    "        axes[0, 2].imshow(x[iTest][2].cpu(), cmap=\"gray\", vmin=0, vmax=1)  # Hillshade\n",
    "        axes[1, 0].imshow(np.transpose(pred_unet[iTest], (1, 2, 0)))\n",
    "        axes[1, 1].imshow(np.transpose(pred_pix2pix[iTest], (1, 2, 0)))\n",
    "        axes[1, 2].imshow(y[iTest].cpu().numpy().transpose(1, 2, 0))\n",
    "\n",
    "        # Cosmetic\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                axes[i, j].set_xticks([])\n",
    "                axes[i, j].set_yticks([])\n",
    "                axes[i, 0].set_axis_off()\n",
    "\n",
    "        axes[0, 0].set_title(\"DEM\")\n",
    "        axes[0, 1].set_title(\"Land Cover\")\n",
    "        axes[0, 2].set_title(\"HS\")\n",
    "        axes[1, 0].set_title(\"Prediction, U-Net\")\n",
    "        axes[1, 1].set_title(\"Prediction, Pix2Pix\")\n",
    "        axes[1, 2].set_title(\"Ground truth\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/pix2pix_test-{testId[iTest]}.png\", dpi=600, bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP29OsO52kDjThAF87cKiQ6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
