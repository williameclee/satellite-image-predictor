{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991e0a19",
   "metadata": {},
   "source": [
    "# Download and Process Satellite Imagery from Google Earth Engine\n",
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd77353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79291a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parameters\n",
    "tile_size = 256  # px\n",
    "tile_scale = 200  # m/px\n",
    "\n",
    "crs = \"EPSG:3857\"\n",
    "tile_width = tile_scale * tile_size\n",
    "time_range = (\"2015-01-01\", \"2025-01-01\")\n",
    "cloud_threshold = 10  # %\n",
    "water_max_ratio = 0.9\n",
    "\n",
    "json_dir = \"training-data/satellite\"\n",
    "if not os.path.exists(json_dir):\n",
    "    os.makedirs(json_dir)\n",
    "\n",
    "json_files = sorted([f for f in os.listdir(json_dir) if f.endswith(\".json\")])\n",
    "print(len(json_files), \"existing JSON files in\", json_dir)\n",
    "last_json = json_files[-1] if json_files else None\n",
    "if last_json:\n",
    "    last_index = int(last_json.split(\"_\")[1])\n",
    "    i_tile = last_index + 1\n",
    "else:\n",
    "    i_tile = 0\n",
    "print(\"Starting with tile index\", i_tile)\n",
    "\n",
    "land = ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")\n",
    "\n",
    "used_ids_file = os.path.join(json_dir, \"used_ids.txt\")\n",
    "\n",
    "used_ids = set()\n",
    "if os.path.exists(used_ids_file):\n",
    "    with open(used_ids_file, \"r\") as f:\n",
    "        used_ids = set(f.read().splitlines())\n",
    "else: \n",
    "    with open(used_ids_file, \"w\") as f:\n",
    "        f.write(\"\")\n",
    "        \n",
    "drive_folder = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72244c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_lat_uniform_area(min_lat_deg, max_lat_deg):\n",
    "    min_lat_rad = math.radians(min_lat_deg)\n",
    "    max_lat_rad = math.radians(max_lat_deg)\n",
    "    u = random.uniform(math.sin(min_lat_rad), math.sin(max_lat_rad))\n",
    "    lat_rad = math.asin(u)\n",
    "    return math.degrees(lat_rad)\n",
    "\n",
    "\n",
    "def export_tile(i_tile):\n",
    "    lon = random.uniform(-180, 180)\n",
    "    lat = random_lat_uniform_area(-60, 80)\n",
    "    point = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "    # Only keep points on land\n",
    "    if land.filterBounds(point).size().getInfo() == 0:\n",
    "        return None, None\n",
    "\n",
    "    s2_collection = (\n",
    "        ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "        .filterDate(time_range[0], time_range[1])\n",
    "        .filterBounds(point)\n",
    "        .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", cloud_threshold))\n",
    "    )\n",
    "    image_ids = s2_collection.aggregate_array(\"system:index\").getInfo()\n",
    "    # find images that have not been used yet\n",
    "    image_ids = [img_id for img_id in image_ids if img_id not in used_ids]\n",
    "    if len(image_ids) == 0:\n",
    "        return None, None\n",
    "    img_id = random.choice(image_ids)\n",
    "    s2 = ee.Image(f\"COPERNICUS/S2_SR_HARMONIZED/{img_id}\")\n",
    "\n",
    "    footprint = s2.geometry()\n",
    "    point = footprint.centroid()\n",
    "    region = point.buffer(tile_width * 1.02 / 2).bounds()  # 1% buffer on each side\n",
    "\n",
    "    i_tile_str = f\"{i_tile:05d}\"\n",
    "\n",
    "    # Export RGB\n",
    "    rgb = (\n",
    "        s2.select([\"B4\", \"B3\", \"B2\"])\n",
    "        .clip(region)\n",
    "        .reproject(crs=crs, scale=tile_scale)\n",
    "        .min(3000)\n",
    "        .divide(3000)\n",
    "        .multiply(255)\n",
    "        .uint8()\n",
    "    )\n",
    "\n",
    "    ee.batch.Export.image.toDrive(\n",
    "        image=rgb,\n",
    "        description=f\"tile_{i_tile_str}_rgb\",\n",
    "        # folder=drive_folder,\n",
    "        fileNamePrefix=f\"tile_{i_tile_str}_rgb\",\n",
    "        region=region,\n",
    "        scale=tile_scale,\n",
    "        crs=crs,\n",
    "        maxPixels=1e9,\n",
    "    ).start()\n",
    "\n",
    "    # Cloud mask\n",
    "    qa = s2.select(\"QA60\")\n",
    "    opaque = qa.bitwiseAnd(1 << 10).gt(0)\n",
    "    cirrus = qa.bitwiseAnd(1 << 11).gt(0)\n",
    "\n",
    "    cld = (\n",
    "        opaque.Or(cirrus)\n",
    "        .rename(\"cloud_mask\")\n",
    "        .clip(region)\n",
    "        .reproject(crs=crs, scale=tile_scale)\n",
    "    )\n",
    "\n",
    "    ee.batch.Export.image.toDrive(\n",
    "        image=cld,\n",
    "        description=f\"tile_{i_tile_str}_cld\",\n",
    "        # folder=drive_folder,\n",
    "        fileNamePrefix=f\"tile_{i_tile_str}_cld\",\n",
    "        region=region,\n",
    "        scale=tile_scale,\n",
    "        crs=crs,\n",
    "        maxPixels=1e9,\n",
    "    ).start()\n",
    "\n",
    "    # Export DEM\n",
    "    dem = (\n",
    "        ee.ImageCollection(\"COPERNICUS/DEM/GLO30\")\n",
    "        .mosaic()\n",
    "        .select(\"DEM\")\n",
    "        .clip(region)\n",
    "        .reproject(crs=crs, scale=tile_scale)\n",
    "        .int16()\n",
    "    )\n",
    "\n",
    "    ee.batch.Export.image.toDrive(\n",
    "        image=dem.clip(region),\n",
    "        description=f\"tile_{i_tile_str}_dem\",\n",
    "        # folder=drive_folder,\n",
    "        fileNamePrefix=f\"tile_{i_tile_str}_dem\",\n",
    "        region=region,\n",
    "        scale=tile_scale,\n",
    "        crs=crs,\n",
    "        maxPixels=1e9,\n",
    "    ).start()\n",
    "\n",
    "    # Export Landcover\n",
    "    landcover = (\n",
    "        ee.Image(\"ESA/WorldCover/v100/2020\")\n",
    "        .clip(region)\n",
    "        .reproject(crs=crs, scale=tile_scale)\n",
    "        .toUint8()\n",
    "    )\n",
    "\n",
    "    esa_original = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]\n",
    "    esa_remapped = [4, 5, 6, 8, 9, 3, 2, 1, 7, 7, 10]\n",
    "    landcover = landcover.remap(esa_original, esa_remapped)\n",
    "\n",
    "    ee.batch.Export.image.toDrive(\n",
    "        image=landcover,\n",
    "        description=f\"tile_{i_tile_str}_lct\",\n",
    "        # folder=drive_folder,\n",
    "        fileNamePrefix=f\"tile_{i_tile_str}_lct\",\n",
    "        region=region,\n",
    "        scale=tile_scale,\n",
    "        crs=crs,\n",
    "        maxPixels=1e9,\n",
    "    ).start()\n",
    "\n",
    "    # Extract auxiliary metadata\n",
    "    solar_zenith = s2.get(\"MEAN_SOLAR_ZENITH_ANGLE\").getInfo()\n",
    "    solar_azimuth = s2.get(\"MEAN_SOLAR_AZIMUTH_ANGLE\").getInfo()\n",
    "    month = ee.Date(s2.get(\"system:time_start\")).get(\"month\").getInfo()\n",
    "\n",
    "    json_data = {\n",
    "        \"solar_zenith\": round(solar_zenith, 2),\n",
    "        \"solar_azimuth\": round(solar_azimuth, 2),\n",
    "        \"month\": month,\n",
    "        \"tile_size\": tile_size,\n",
    "        \"tile_scale\": tile_scale,\n",
    "        \"centre_lon\": round(point.coordinates().get(0).getInfo(), 4),\n",
    "        \"centre_lat\": round(point.coordinates().get(1).getInfo(), 4),\n",
    "        \"tiles\": {\n",
    "            \"rgb\": f\"tile_{i_tile_str}_rgb.tif\",\n",
    "            \"dem\": f\"tile_{i_tile_str}_dem.tif\",\n",
    "            \"lct\": f\"tile_{i_tile_str}_lct.tif\",\n",
    "            \"cld\": f\"tile_{i_tile_str}_cld.tif\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(f\"{json_dir}/tile_{i_tile_str}_met.json\", \"w\") as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "    return json_data, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# n_tiles = 18000\n",
    "n_tiles = i_tile + 300\n",
    "\n",
    "while i_tile < n_tiles:\n",
    "    try:\n",
    "        json_data, img_id = export_tile(i_tile)\n",
    "        if json_data is not None:\n",
    "            print(f\"Tile {i_tile} processed.\")\n",
    "            i_tile += 1\n",
    "            used_ids.add(img_id)\n",
    "            with open(used_ids_file, \"w\") as f:\n",
    "                json.dump(list(used_ids), f, indent=2)\n",
    "    except Exception as e:\n",
    "        # if failed, wait 1 minute and retry\n",
    "        print(f\"Tile {i_tile} failed with error: {e}, retrying in 3 minutes...\")\n",
    "        time.sleep(60 * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383f3fa",
   "metadata": {},
   "source": [
    "## Quality check and cleaning\n",
    "### Refactoring file names (no longer needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def refactor_metadata(json_path, save=False):\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "        # Check if tile keys are already reformatted\n",
    "        tile_keys = [\"tile_rgb\", \"tile_dem\", \"tile_lct\", \"tile_cld\"]\n",
    "        if \"tiles\" not in meta:\n",
    "            tile_keys_present = [key for key in tile_keys if key in meta]\n",
    "            meta[\"tiles\"] = {\n",
    "                key.replace(\"tile_\", \"\"): meta[key] for key in tile_keys_present\n",
    "            }\n",
    "\n",
    "            # Remove old keys\n",
    "            for key in tile_keys_present:\n",
    "                del meta[key]\n",
    "\n",
    "    if save:\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump(meta, f, indent=2)\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a07e42",
   "metadata": {},
   "source": [
    "### Purging duplicate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "input_dir = \"training-data/satellite/\"\n",
    "json_files = sorted(glob.glob(os.path.join(input_dir, \"tile_*_met.json\")))\n",
    "\n",
    "\n",
    "seen_centers = {}\n",
    "duplicate_count = 0\n",
    "\n",
    "for json_path in json_files:\n",
    "    with open(json_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "        centre = (\n",
    "            meta[\"centre_lon\"],\n",
    "            meta[\"centre_lat\"],\n",
    "            meta[\"solar_azimuth\"],\n",
    "            meta[\"solar_zenith\"],\n",
    "            meta[\"tile_scale\"],\n",
    "        )\n",
    "\n",
    "        if centre in seen_centers:\n",
    "            keys = meta[\"tiles\"].keys()\n",
    "            tiles = [os.path.join(input_dir, meta[\"tiles\"][key]) for key in keys]\n",
    "            for tile in tiles:\n",
    "                os.remove(tile)\n",
    "            os.remove(json_path)\n",
    "            duplicate_count += 1\n",
    "        else:\n",
    "            seen_centers[centre] = json_path\n",
    "\n",
    "print(f\"Purged {duplicate_count} duplicate centers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e9d2a",
   "metadata": {},
   "source": [
    "### Remove incomplete/invalid tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"training-data/satellite/\"\n",
    "all_files = sorted(glob.glob(os.path.join(input_dir, \"tile_*\")))\n",
    "img_files = sorted(glob.glob(os.path.join(input_dir, \"*.tif\")))\n",
    "\n",
    "# remove files with paranthesis in the name\n",
    "img_files = [f for f in img_files if \"(\" in f]\n",
    "\n",
    "for f in img_files:\n",
    "    img_base_name = os.path.basename(f)\n",
    "    tile_id = img_base_name.split(\"_\")[1]\n",
    "    invalid_files = [f for f in all_files if tile_id in f]\n",
    "    for invalid_file in invalid_files:\n",
    "        if not os.path.exists(invalid_file):\n",
    "            continue\n",
    "        os.remove(invalid_file)\n",
    "        print(f\"Removed {invalid_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"training-data/satellite/\"\n",
    "json_files = sorted(glob.glob(os.path.join(input_dir, \"tile_*_met.json\")))\n",
    "\n",
    "\n",
    "for json_path in json_files:\n",
    "    with open(json_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "        keys = meta[\"tiles\"].keys()\n",
    "        img_tiles = [os.path.join(input_dir, meta[\"tiles\"][key]) for key in keys]\n",
    "        if not all(os.path.exists(tile) for tile in img_tiles):\n",
    "            print(f\"Missing tiles for {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cb8a4",
   "metadata": {},
   "source": [
    "### Checking and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import rasterio\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_from_json(\n",
    "    json_path,\n",
    "    input_dir,\n",
    "    output_dir,\n",
    "    tile_size=256,\n",
    "    water_max_ratio=0.9,\n",
    "    max_black_ratio=0.2,\n",
    "    max_white_ratio=0.7,\n",
    "    rotate=False,\n",
    "    be_quiet=False,\n",
    "):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        if not be_quiet:\n",
    "            print(f\"Created output folder {output_dir}\")\n",
    "\n",
    "    tile_base_name = os.path.basename(json_path).replace(\"_met.json\", \"\")\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "        # Check tile size is what we want\n",
    "        if meta.get(\"tile_size\", None) is not tile_size:\n",
    "            return False\n",
    "        # Assign northing direction\n",
    "        meta[\"north_dir\"] = 0 / 360  # in normalised azimuth\n",
    "\n",
    "    tile_size = meta.get(\"tile_size\", 256)\n",
    "\n",
    "    keys = meta.get(\"tiles\", {}).keys()\n",
    "    input_paths = []\n",
    "    output_paths = []\n",
    "\n",
    "    for key in keys:\n",
    "        input_file = meta.get(\"tiles\").get(key)\n",
    "        input_path = os.path.join(input_dir, input_file)\n",
    "\n",
    "        if not os.path.exists(input_path):\n",
    "            if not be_quiet:\n",
    "                print(f\"File {input_path} not found, skipping tile\")\n",
    "            return False\n",
    "\n",
    "        if key == \"dem\":\n",
    "            with rasterio.open(input_path, \"r\") as src:\n",
    "                dem = src.read(1)\n",
    "                dem[np.isnan(dem)] = 0\n",
    "            # skip if > 90% of pixels are water\n",
    "            if np.mean(dem == 0) > water_max_ratio:\n",
    "                if not be_quiet:\n",
    "                    print(f\"Skipping tile {input_file} due to too much water\")\n",
    "                return False\n",
    "\n",
    "        if key == \"rgb\":\n",
    "            with rasterio.open(input_path, \"r\") as src:\n",
    "                rgb = src.read()\n",
    "                rgb_brightness_approx = np.mean(rgb, axis=0)\n",
    "\n",
    "            # skip if too black\n",
    "            if np.mean(rgb_brightness_approx < 5) > max_black_ratio:\n",
    "                if not be_quiet:\n",
    "                    print(f\"Skipping tile {input_file} due to too black\")\n",
    "                return False\n",
    "\n",
    "            # skip if too white\n",
    "            if np.mean(rgb_brightness_approx > 250) > max_white_ratio:\n",
    "                if not be_quiet:\n",
    "                    print(f\"Skipping tile {input_file} due to too white\")\n",
    "                return False\n",
    "\n",
    "        output_path = os.path.join(output_dir, input_file)\n",
    "\n",
    "        input_paths.append(input_path)\n",
    "        output_paths.append(output_path)\n",
    "\n",
    "    if rotate:\n",
    "        rotate_range = [0, 90, 180, 270]\n",
    "    else:\n",
    "        rotate_range = [0]\n",
    "    for rotation in rotate_range:\n",
    "        meta[\"north_dir\"] = rotation / 360  # in normalised azimuth\n",
    "        tile_rot_base_name = tile_base_name + f\"_r{rotation:03d}\"\n",
    "        for input_path, key in zip(input_paths, keys):\n",
    "            output_name = tile_rot_base_name + f\"_{key}\"\n",
    "            output_path = os.path.join(output_dir, output_name + \".tif\")\n",
    "            truncate_tile(\n",
    "                input_path,\n",
    "                size=[tile_size, tile_size],\n",
    "                output_path=output_path,\n",
    "                rotation=rotation,\n",
    "            )\n",
    "            meta[\"tiles\"][key] = output_name + \".tif\"\n",
    "\n",
    "        json_name = tile_rot_base_name + \"_met.json\"\n",
    "        json_output = os.path.join(output_dir, json_name)\n",
    "        with open(json_output, \"w\") as f:\n",
    "            json.dump(meta, f, indent=2)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def truncate_tile(input_path, size=[256, 256], output_path=None, rotation=0):\n",
    "    if output_path is None:\n",
    "        output_path = input_path\n",
    "\n",
    "    # check output folder exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output folder {output_dir}\")\n",
    "    # check input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        raise ValueError(f\"File {input_path} not found\")\n",
    "\n",
    "    with rasterio.open(input_path, \"r\") as input_img:\n",
    "        img = input_img.read()\n",
    "\n",
    "        # Truncate or crop to 256x256 from top-left\n",
    "        try:\n",
    "            img_cropped = img[:, : size[0], : size[1]]\n",
    "        except Exception as e:\n",
    "            print(img.shape)\n",
    "            raise ValueError(\n",
    "                f\"Error cropping image {input_path} to {size[0]}x{size[1]}: {e}\"\n",
    "            )\n",
    "\n",
    "    if rotation != 0:\n",
    "        # Rotate the image\n",
    "        img_cropped = np.rot90(img_cropped, k=-rotation // 90, axes=(1, 2))\n",
    "\n",
    "        # Update dataset dimensions in place\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=size[0],\n",
    "        width=size[1],\n",
    "        count=input_img.count,\n",
    "        dtype=img.dtype,\n",
    "        crs=input_img.crs,\n",
    "        transform=input_img.transform,\n",
    "    ) as output_img:\n",
    "        output_img.write(img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "json_files = sorted(glob.glob(\"training-data/satellite/tile_*_met.json\"))\n",
    "# json_files = json_files[:10]  # for testing\n",
    "\n",
    "print(f\"Found {len(json_files)} JSON files to process\")\n",
    "\n",
    "tile_size = 256\n",
    "rotate = False\n",
    "output_dir = f\"training-data/satellite-T{tile_size:04d}-R{int(rotate)}\"\n",
    "\n",
    "success_count = 0\n",
    "\n",
    "for json_path in tqdm(json_files, desc=\"Processing tiles\"):\n",
    "    is_success = process_from_json(\n",
    "        json_path,\n",
    "        \"training-data/satellite/\",\n",
    "        output_dir,\n",
    "        tile_size=tile_size,\n",
    "        rotate=rotate,\n",
    "        water_max_ratio=0.9,\n",
    "        max_black_ratio=0.1,\n",
    "        max_white_ratio=0.6,\n",
    "        be_quiet=True,\n",
    "    )\n",
    "    if is_success:\n",
    "        success_count += 1\n",
    "\n",
    "print(\n",
    "    f\"Processed {success_count} ({success_count/len(json_files)*100}%) tiles successfully.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
